{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning: deep learning for vertically partitioned data \n",
    "\n",
    "In this notebook, we provide a simple example of how to perform a **vertical** federated learning experiment with the help of the Sherpa.ai Federated Learning framework. \n",
    "As opposed to the horizontal federated learning paradigm, in a vertical federated learning setting (see e.g. [Federated Machine Learning: Concept and Applications](https://arxiv.org/abs/1902.04885)) the different nodes possess the same samples, but different features. \n",
    "A practical example being that of a local on-line shop and an insurance company: both entities might have matching customers (samples), but the information (features) each entity possesses about the customers is of different nature. \n",
    "We are going to use a synthetic dataset and a neural network model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "We use `sklearn` module for generating synthetic databases. \n",
    "Moreover, in order to simulate a vertically partitioned training data, we randomly split the features of the created dataset among the clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "n_features = 20\n",
    "n_classes = 2\n",
    "n_samples = 15000\n",
    "\n",
    "x, y = make_classification(\n",
    "    n_samples=n_samples, n_features=n_features, \n",
    "    n_redundant=0, n_repeated=0, n_classes=n_classes, \n",
    "    n_clusters_per_class=1, flip_y=0.1, class_sep=0.4, random_state=123)\n",
    "x = pd.DataFrame(x)\n",
    "\n",
    "x_train = x[:int(n_samples * 0.8)]\n",
    "x_test = x[int(n_samples * 0.8):]\n",
    "y_train = y[:int(n_samples * 0.8), ]\n",
    "y_test = y[int(n_samples * 0.8):, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_general(x_train, x_test, m, seed=None):\n",
    "    \"\"\"\n",
    "    Splits two dataframes with the same columns (and possibly different number of rows)\n",
    "    into M dataframes along the columns.\n",
    "\n",
    "    # Arguments:\n",
    "        X_train: dataframe with the training features\n",
    "        y_test: dataframe with the test features\n",
    "        m: number of clients\n",
    "        seed: reproducible results (optional)\n",
    "    # Returns:\n",
    "        X_train_client: dictionary where the key is the clientId and the value is a dataframe with the training features\n",
    "        X_test_client: dictionary where the key is the clientId and the value is a dataframe with the test features\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n = x_train.shape[1]  # total number of features\n",
    "    features = np.arange(n)\n",
    "    np.random.shuffle(features)\n",
    "    index_client = np.sort(\n",
    "        np.append(np.random.choice(np.arange(1, n), m - 1), [0, n]))  # index where the features are split\n",
    "\n",
    "    features_client = {i: features[index_client[i]:index_client[i + 1]] for i in range(m)}\n",
    "    x_train_client = {i: x_train[features_client[i]] for i in range(m)}\n",
    "    x_test_client = {i: x_test[features_client[i]] for i in range(m)}\n",
    "\n",
    "    return x_train_client, x_test_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vertically split dataset: split the features among clients\n",
    "M = 2  # number of clients\n",
    "x_train_client, x_test_client = split_data_general(x_train, x_test, M, seed=11)\n",
    "train_labels_client = {0:None, 1:None}\n",
    "print(\"Private data client 0: \", x_train_client[0].shape)\n",
    "print(\"Private data client 1: \", x_train_client[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make federated data: \n",
    "from shfl.private.data import LabeledData\n",
    "from shfl.private.federated_operation import FederatedData\n",
    "from shfl.data_distribution.data_distribution import DataDistribution\n",
    "\n",
    "class DataDistributionFromList():\n",
    "    \"\"\"\n",
    "        Data (and labels) are already in a list-type, \n",
    "        where each entry contains data of one node\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_data_federated(self, federated_train_data, federated_train_label):\n",
    "        federated_data = FederatedData()\n",
    "        num_nodes = len(federated_train_label)\n",
    "        for node in range(num_nodes):\n",
    "            node_data = LabeledData(federated_train_data[node], federated_train_label[node])\n",
    "            federated_data.add_data_node(node_data)\n",
    "\n",
    "        return federated_data\n",
    "    \n",
    "data_distribution = DataDistributionFromList()\n",
    "federated_data = data_distribution.get_data_federated(x_train_client, train_labels_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated data operation: need to transpose\n",
    "from shfl.private import FederatedTransformation\n",
    "\n",
    "class Transpose(FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        if labeled_data.data is not None:\n",
    "            labeled_data.data = labeled_data.data.T\n",
    "        \n",
    "federated_data.apply_data_transformation(Transpose());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check federated data:\n",
    "from shfl.private.data import UnprotectedAccess\n",
    "\n",
    "federated_data.configure_data_access(UnprotectedAccess());\n",
    "federated_data[0].query()\n",
    "#federated_data[0].query().data\n",
    "#federated_data[0].query().label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation of the Federated Government is proposed to change as follows: \n",
    " - The Federated Government \"self\" is intended as a *Coordinator*: it schedules the federated computations, but does not have any other function (no data, no model)\n",
    " - The Federated Data is composed by nodes that can have multiple functions: train, store data, aggregate, make auxiliary computations, predictions\n",
    " - In particular, the Server is itself a *node* of the Federated Data: it might aggregate, but might also contain data and train on them\n",
    " \n",
    "Note that in this perspective, each node is assigned a potentially *different model*. \n",
    "For example in Horizontal FL, all nodes have the same model, and the server node has also the aggregation function in its model as an attribute but do not train and does not possess any data.\n",
    "Instead in Vertical FL the client nodes have a different model with respect the server node, which in turn can aggregate, train and possess its own data.\n",
    "\n",
    "In addition, note that the distinction between client and server is *only virtual* and not necessarily physical, since a single node might be both client and server, allowing multiple roles for the same physical node.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model:\n",
    "First we compute a benchmark on centralized data using `sk-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_prediction, save_path=None):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prediction)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if save_path is not None: \n",
    "        plt.savefig(save_path, bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model Benchmark on centralized data using sk-learn:\n",
    "#clf_linear = MLPClassifier(hidden_layer_sizes=(1,), max_iter=10000, shuffle=False, random_state=321).fit(x_train, y_train)\n",
    "clf_linear = LogisticRegression(random_state=123).fit(x_train, y_train)\n",
    "y_prediction = clf_linear.predict_proba(x_test)[:, 1]\n",
    "plot_roc(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the federated experiment with `shfl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model builder can also be a list of models\n",
    "from shfl.federated_government.vertical_federated_deep_learning import FederatedGovernmentVertical\n",
    "from shfl.model.vertical_deep_learning_model import VerticalNeuralNetClient\n",
    "from shfl.model.vertical_deep_learning_model import VerticalLogLinearServer\n",
    "from shfl.private.federated_operation import FederatedDataNode\n",
    "\n",
    "\n",
    "class VerticalServerDataNode(FederatedDataNode):\n",
    "    \"\"\"\n",
    "        This class represents a type Server [DataNode](../data_node) in a FederatedData.\n",
    "        Extends DataNode allowing calls to methods without explicit private data identifier,\n",
    "        assuming access to the Server's data (if any).\n",
    "        Aggregate weights from all data nodes in the server model and\n",
    "        updates the server. In this vertical architecture, the server possesses part\n",
    "        of the model, thus the aggregation is actually a server's training.\n",
    "        It supports Adaptive Differential Privacy through Privacy Filters\n",
    "\n",
    "        # Arguments:\n",
    "            federated_data: the set of client nodes\n",
    "            model: python object representing the model of the server node\n",
    "            aggregator: python object representing the type of aggregator to use\n",
    "            data: optional, server's private data\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, federated_data, model, aggregator, data=None):\n",
    "        super().__init__(federated_data_identifier=str(id(federated_data)))\n",
    "        self._federated_data = federated_data\n",
    "        self.model = model\n",
    "        self._aggregator = aggregator\n",
    "        self.set_private_data(data)\n",
    "        \n",
    "    \n",
    "    def aggregate_weights(self):\n",
    "        \n",
    "        embeddings = [data_node.query_model()\n",
    "                      for data_node in self._federated_data]\n",
    "        \n",
    "        self.train_model(embeddings=embeddings)\n",
    "        \n",
    "    def compute_loss(self):\n",
    "        \"\"\"\n",
    "        Evaluate loss on the train set.\n",
    "        \"\"\"\n",
    "        embeddings = [data_node.query_model()\n",
    "                      for data_node in self._federated_data]\n",
    "        \n",
    "        loss = self.query(server_node=self, embeddings=embeddings)\n",
    "        \n",
    "    def evaluate_collaborative_model(self, data_test, label_test):\n",
    "        \"\"\"\n",
    "        Evaluation of the performance of the collaborative model.\n",
    "\n",
    "        # Arguments:\n",
    "            test_data: test dataset (global)\n",
    "            test_label: corresponding labels to test dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute embeddings (CLIENTS)\n",
    "        embeddings = [data_node.predict(data_test[data_node_key])\n",
    "                      for data_node, data_node_key in\n",
    "                      zip(self._federated_data, data_test.keys())]\n",
    "\n",
    "        # Compute prediction (SERVER)\n",
    "        prediction = self.predict(embeddings)\n",
    "        print(\"Distributed model test AUC: \"\n",
    "              + str(self.performance(prediction, label_test)))\n",
    "\n",
    "        return prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a third node that acts as server:\n",
    "# NOTE: how to assign the data to the server? \n",
    "# it should be done before actually configuring server's model. \n",
    "# POSSIBLE SOLUTION: maybe first create a FederatedNode (like we do for FederatedData),\n",
    "# and later configure it's model, aggregator, and assign federated_data?\n",
    "# This way, server's data would be secured. \n",
    "# Maybe we can use this solution: https://stackoverflow.com/questions/1216356/is-it-safe-to-replace-a-self-object-by-another-object-of-the-same-type-in-a-meth\n",
    "server_node = VerticalServerDataNode(\n",
    "        federated_data=federated_data, \n",
    "        model=VerticalLogLinearServer(), \n",
    "        aggregator=None,\n",
    "        data=LabeledData(None, y_train))\n",
    "\n",
    "model_nodes = [VerticalNeuralNetClient(n_features=x_train_client[0].shape[1]),\n",
    "               VerticalNeuralNetClient(n_features=x_train_client[1].shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.private.data import DataAccessDefinition\n",
    "\n",
    "class ComputeLoss(DataAccessDefinition):\n",
    "    def apply(self, data, **kwargs): \n",
    "        embeddings = kwargs.get(\"embeddings\")\n",
    "        node = kwargs.get(\"server_node\")\n",
    "        loss = server_node._model.compute_loss(\n",
    "                embeddings, data.label)\n",
    "        \n",
    "        print(\"Collaborative model train loss: \" + str(loss))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class QueryMetaParameters(DataAccessDefinition):\n",
    "    def apply(self, model):\n",
    "        \"\"\"Returns embeddings (or their gradients) as computed by the local model.\"\"\"\n",
    "        return model.get_meta_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data access to nodes and server\n",
    "federated_data.configure_model_access(QueryMetaParameters())\n",
    "server_node.configure_model_access(QueryMetaParameters())\n",
    "server_node.configure_data_access(ComputeLoss())   \n",
    "\n",
    "print(federated_data[1]._model_access_policy)\n",
    "print(server_node._model_access_policy)\n",
    "print(server_node._private_data_access_policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create federated government and run training:\n",
    "\n",
    "federated_government = FederatedGovernmentVertical(model_nodes, \n",
    "                                                   federated_data, \n",
    "                                                   server_node=server_node)\n",
    "\n",
    "x_test_client_transpose = {i: x_test_client[i].T for i in range(len(x_test_client))}\n",
    "federated_government.run_rounds(n=20001, \n",
    "                                test_data=x_test_client_transpose, \n",
    "                                test_label=y_test, \n",
    "                                print_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = federated_government._server.evaluate_collaborative_model(\n",
    "    data_test=x_test_client_transpose, label_test=y_test)\n",
    "plot_roc(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear model:\n",
    "Analogously as before, we run the non-linear model on centralized data using `sk-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-linear benchmark\n",
    "clf_non_linear = MLPClassifier(hidden_layer_sizes=(3,), max_iter=10000, shuffle=False, random_state=3221).fit(x_train, y_train)\n",
    "y_prediction = clf_non_linear.predict_proba(x_test)[:, 1]\n",
    "plot_roc(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the federated experiment using non-linear deep neural network local model with `shfl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nodes = [VerticalNeuralNetClient(n_features=x_train_client[0].shape[1], \n",
    "                                       layer_dims=[3]),\n",
    "               VerticalNeuralNetClient(n_features=x_train_client[1].shape[1], \n",
    "                                       layer_dims=[3])]\n",
    "\n",
    "federated_government = FederatedGovernmentVertical(model_nodes, \n",
    "                                                   federated_data, \n",
    "                                                   server_node=server_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government.run_rounds(n=100001, \n",
    "                                test_data=x_test_client_transpose, \n",
    "                                test_label=y_test, \n",
    "                                print_freq=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = federated_government._server.evaluate_collaborative_model(\n",
    "    data_test=x_test_client_transpose, label_test=y_test)\n",
    "plot_roc(y_test, y_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SherpaFL_py37",
   "language": "python",
   "name": "sherpafl_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
